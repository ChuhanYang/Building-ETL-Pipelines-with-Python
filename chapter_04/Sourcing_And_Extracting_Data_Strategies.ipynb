{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e086144c",
   "metadata": {},
   "source": [
    "## Getting Started with Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5859a6",
   "metadata": {},
   "source": [
    "### API Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdade052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import API-related Python modules \n",
    "import json \n",
    "import certifi \n",
    "# import ssl,  if necessary\n",
    "import urllib3 \n",
    "from urllib3 import request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials for the web request\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where()) \n",
    "\n",
    "# Load data from the API request as a dataframe\n",
    "data = json.loads(http.request('GET', url).data.decode('utf-8')) \n",
    "api_df = pd.json_normalize(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049c43c",
   "metadata": {},
   "source": [
    "### Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python db \n",
    "import sqlite3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame \n",
    "with sqlite3.connect(\"movies.sqlite\") as conn: \n",
    "    df_sqlite = pd.read_sql(\"SELECT * from movies\", conn) \n",
    "\n",
    "# Print the first five rows\n",
    "df_sqlite.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480146dd",
   "metadata": {},
   "source": [
    "### Data from Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import numpy as np  \n",
    "from unicodedata import normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39648db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HTML variable \n",
    "html_source = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)' \n",
    "\n",
    "# Import the data to organize ‘by country’ \n",
    "html_df = pd.read_html(html_source, match='by country') \n",
    "\n",
    "# Let's see how many tables are there with tag ' by county' \n",
    "print(len(df_html)) # There are 4 tables \n",
    "\n",
    "# Let's see the first table \n",
    "df_html[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80cd19",
   "metadata": {},
   "source": [
    "## Data Extraction Pipeline using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules  \n",
    "import json  \n",
    "import sqlite3  \n",
    "import certifi  \n",
    "import urllib3\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9d1b5",
   "metadata": {},
   "source": [
    "### Creating a Data Extraction Pipeline using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d729ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import CSV Data  \n",
    "def source_data_from_csv(csv_file_name):  \n",
    "    try:  \n",
    "        df_csv = pd.read_csv(csv_file_name)  \n",
    "    except Exception as e:  \n",
    "        df_csv = pd.DataFrame()  \n",
    "    return df_csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import Parquet Data  \n",
    "def source_data_from_parquet(parquet_file_name):  \n",
    "    try:  \n",
    "        df_parquet = pd.read_parquet(parquet_file_name)  \n",
    "    except Exception as e:  \n",
    "        df_parquet = pd.DataFrame()  \n",
    "    return df_parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import API Data  \n",
    "def source_data_from_api(api_endpoint):  \n",
    "    try:  \n",
    "        # Create a Pool manager that can be used to read the API response  \n",
    "        http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())  \n",
    "        api_response = http.request('GET', api_endpoint)  \n",
    "        apt_status = api_response.status\n",
    "        \n",
    "        # Check if API is available to retrive the data  \n",
    "        if apt_status == 200:\n",
    "            data = json.loads(api_response.data.decode('utf-8'))  \n",
    "            df_api = pd.json_normalize(data)  \n",
    "        \n",
    "        # Sometimes we get certificate error.  \n",
    "        else: \n",
    "            df_api = pd.Dataframe()  \n",
    "            \n",
    "    # We should never silence certificate errors as this may cause a security threat.          \n",
    "    except Exception as e:\n",
    "        df_api = pd.DataFrame()  \n",
    "    return df_api  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import SQL lite Data  \n",
    "def source_data_from_table(db_name, table_name):  \n",
    "    try:  \n",
    "        # Read sqlite query results into a pandas DataFrame  \n",
    "        with sqlite3.connect(db_name) as conn:  \n",
    "            df_table = pd.read_sql(f\"SELECT * from {table_name}\", conn)  \n",
    "\n",
    "    except Exception as e:  \n",
    "        df_table = pd.DataFrame()  \n",
    "    return df_table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd54e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import Webpage Data  \n",
    "def source_data_from_webpage(web_page_url, matching_keyword):  \n",
    "    try:  \n",
    "        # Read webpage table into a pandas DataFrame  \n",
    "        df_html = pd.read_html(web_page_url, match=matching_keyword)  \n",
    "        df_html = df_html[0]  \n",
    "\n",
    "    except Exception as e:  \n",
    "        df_html = pd.DataFrame()  \n",
    "    return df_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Import All Data Sources  \n",
    "def extracted_data_files():  \n",
    "\n",
    "    \"\"\"  \n",
    "    Extract data from all source systems for loading data into VSA(Virtual Staging Area)  \n",
    "    :return: example dataframes of relevant input data sources  \n",
    "    \"\"\"  \n",
    "\n",
    "    # define all data sources  \n",
    "    parquet_file_name = \"data/yellow_tripdata_2022-01.parquet\"  \n",
    "    csv_file_name = \"data/h9gi-nx95.csv\"  \n",
    "    api_endpoint = \"https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500\"  \n",
    "    db_name = \"data/movies.sqlite\"  \n",
    "    table_name = \"movies\" \n",
    "    web_page_url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"  \n",
    "    matching_keyword = \"by country\"  \n",
    "\n",
    "    # import all data types into dataframes\n",
    "    df_parquet, df_csv, df_api, df_table, df_html = (source_data_from_parquet(parquet_file_name),  \n",
    "                                                     source_data_from_csv(csv_file_name),  \n",
    "                                                     source_data_from_api(api_endpoint),  \n",
    "                                                     source_data_from_table(db_name, table_name),  \n",
    "                                                     source_data_from_webpage(web_page_url, matching_keyword))     \n",
    "\n",
    "    return df_parquet, df_csv, df_api, df_table, df_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it Out \n",
    "df_parquit,_,_,_,_ = extraction_functional.extracted_data() \n",
    "df_parquit.head() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
